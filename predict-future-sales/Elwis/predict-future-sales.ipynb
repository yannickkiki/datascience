{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/sales_train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "sample_submit = pd.read_csv(\"../input/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the train_shape: \",train.shape);\n",
    "print(\"the submission shape\",sample_submit.shape )\n",
    "sample_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colums of sample_submit\n",
    "print(\"colums of sample_submit:\", sample_submit.columns)\n",
    "#colums of train\n",
    "print(\"colums of train:\", train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cleanning data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicate row\n",
    "train = train.drop_duplicates()\n",
    "# check if any value in a Series is Missing\n",
    "if train.isnull().values.any():\n",
    "    print(\"ha\")\n",
    "    train = train.dropna()\n",
    "#remove date and item_price\n",
    "train = train.drop(labels = ['date', 'item_price'], axis = 1)\n",
    "#need to create item_cnt_month  in train \n",
    "train = train.groupby(['date_block_num','shop_id', 'item_id'])['item_cnt_day'].sum().reset_index()\n",
    "#rename item_cnt_day into item_cnt_month\n",
    "train = train.rename(index=str, columns = {\"item_cnt_day\":\"item_cnt_month\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change columns\n",
    "train = train.pivot_table(index=['item_id','shop_id'], columns='date_block_num',values='item_cnt_month',fill_value=0).reset_index()\n",
    "#database = fusion(test et train)\n",
    "database = pd.merge(test,train,on=['item_id','shop_id'], how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just to see database \n",
    "database.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = database.iloc[:,3:37].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "train_scaled = sc.fit_transform(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train,Y_train\n",
    "Y_train = train_scaled[:,33]\n",
    "X_train = train_scaled[:,0:33]\n",
    "#X_test\n",
    "X_test = train_scaled[:,1:]\n",
    "print(\"Y_train shape:\",Y_train.shape)\n",
    "print(\"X_train shape:\",X_train.shape)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "Y_train = np.reshape(Y_train, (Y_train.shape[0], 1))\n",
    "print(\"Y_train re-shape:\",Y_train.shape)\n",
    "print(\"X_train re-shape:\",X_train.shape)\n",
    "print(\"X_test re-shape:\",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**# Building the RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "#model layer\n",
    "model = Sequential()\n",
    "model.add(LSTM(16, input_shape=(X_train.shape[1], X_train.shape[2]),return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"adam\", loss='mse', metrics=[\"mse\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=200, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label= 'loss(mse)')\n",
    "plt.plot(np.sqrt(history.history['mean_squared_error']), label= 'rmse')\n",
    "plt.legend(loc=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prediction = model.predict(X_test).clip(0., 20.)\n",
    "prediction = pd.DataFrame(Y_prediction , columns=['item_cnt_month'])\n",
    "prediction.to_csv('submission.csv',index_label='ID')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
