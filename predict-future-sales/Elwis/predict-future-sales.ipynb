{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/sales_train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\nsample_submit = pd.read_csv(\"../input/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Description**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"the train_shape: \",train.shape);\nprint(\"the submission shape\",sample_submit.shape )\nsample_submit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#colums of sample_submit\nprint(\"colums of sample_submit:\", sample_submit.columns)\n#colums of train\nprint(\"colums of train:\", train.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Cleanning data***"},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop duplicate row\ntrain = train.drop_duplicates()\n# check if any value in a Series is Missing\nif train.isnull().values.any():\n    print(\"ha\")\n    train = train.dropna()\n#remove date and item_price\ntrain = train.drop(labels = ['date', 'item_price'], axis = 1)\n#need to create item_cnt_month  in train \ntrain = train.groupby(['date_block_num','shop_id', 'item_id'])['item_cnt_day'].sum().reset_index()\n#rename item_cnt_day into item_cnt_month\ntrain = train.rename(index=str, columns = {\"item_cnt_day\":\"item_cnt_month\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#change columns\ntrain = train.pivot_table(index=['item_id','shop_id'], columns='date_block_num',values='item_cnt_month',fill_value=0).reset_index()\n#database = fusion(test et train)\ndatabase = pd.merge(test,train,on=['item_id','shop_id'], how='left').fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#just to see database \ndatabase.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = database.iloc[:,3:37].values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Scaling\nfrom sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler(feature_range = (0, 1))\ntrain_scaled = sc.fit_transform(train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train,Y_train\nY_train = train_scaled[:,33]\nX_train = train_scaled[:,0:33]\n#X_test\nX_test = train_scaled[:,1:]\nprint(\"Y_train shape:\",Y_train.shape)\nprint(\"X_train shape:\",X_train.shape)\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\nY_train = np.reshape(Y_train, (Y_train.shape[0], 1))\nprint(\"Y_train re-shape:\",Y_train.shape)\nprint(\"X_train re-shape:\",X_train.shape)\nprint(\"X_test re-shape:\",X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**# Building the RNN**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout\n#model layer\nmodel = Sequential()\nmodel.add(LSTM(16, input_shape=(X_train.shape[1], X_train.shape[2]),return_sequences=True))\nmodel.add(Dropout(0.5))\nmodel.add(LSTM(32))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.compile(optimizer=\"adam\", loss='mse', metrics=[\"mse\"])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train, Y_train, batch_size=200, epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['loss'], label= 'loss(mse)')\nplt.plot(np.sqrt(history.history['mean_squared_error']), label= 'rmse')\nplt.legend(loc=1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Prediction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_prediction = model.predict(X_test).clip(0., 20.)\nprediction = pd.DataFrame(Y_prediction , columns=['item_cnt_month'])\nprediction.to_csv('submission.csv',index_label='ID')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}